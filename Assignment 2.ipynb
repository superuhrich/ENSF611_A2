{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f86925",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T18:59:45.898585700Z",
     "start_time": "2023-10-02T18:59:45.083630Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yellowbrick\n",
    "from yellowbrick import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X: (4600, 57), with type <class 'pandas.core.frame.DataFrame'>\n",
      "Size of y: (4600,), with type <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "X, Y = yellowbrick.datasets.loaders.load_spam(data_home=None, return_dataset=False)\n",
    "\n",
    "print(f\"Size of X: {X.shape}, with type {type(X)}\")\n",
    "print(f\"Size of y: {Y.shape}, with type {type(Y)}\")\n",
    "\n",
    "\n",
    "# TO DO: Print size and type of X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in x: 0\n",
      "missing values in y: 0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "missingValuesX = X.isna().sum().sum()\n",
    "missingValuesY = Y.isnull().sum()\n",
    "\n",
    "print(f\"Missing values in x: {missingValuesX}\")\n",
    "print(f\"missing values in y: {missingValuesY}\")\n",
    "\n",
    "#no missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create X_small and y_small \n",
    "XSmall, _, YSmall, _ = train_test_split(X, Y, test_size=0.95, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1876dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Dataset  DataSize  TrainingAccuracy  ValidationAccuracy\n",
      "0     fullDataSet      4600          0.927446            0.936957\n",
      "1    smallDataSet       230          0.934783            0.913043\n",
      "2  paritalDataSet      4600          0.614946            0.593478\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "\n",
    "\n",
    "#For the partia data set\n",
    "XPartial = X.iloc[:,:2]\n",
    "\n",
    "# goign to store the datasets in a nested dictionary\n",
    "datasets = {\n",
    "    'fullDataSet': {'X': X, 'Y': Y},\n",
    "    'smallDataSet': {'X': XSmall, 'Y': YSmall},\n",
    "    'paritalDataSet': {'X': XPartial, 'Y': Y }\n",
    "}\n",
    "\n",
    "results = pd.DataFrame(columns=['Dataset','DataSize', 'TrainingAccuracy', 'ValidationAccuracy'])\n",
    "\n",
    "for datasetName, data in datasets.items():\n",
    "    x = data['X']\n",
    "    y = data['Y']\n",
    "\n",
    "\n",
    "    # Create the training sets\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Train the model\n",
    "    model = LogisticRegression(max_iter=2000)\n",
    "    model.fit(xTrain, yTrain)\n",
    "\n",
    "    #Predict and calculate accuracy\n",
    "    yTrainPred = model.predict(xTrain)\n",
    "    yTestPred = model.predict(xTest)\n",
    "\n",
    "    trainAccuracy = accuracy_score(yTrain, yTrainPred)\n",
    "    dataAccuracy = accuracy_score(yTest, yTestPred)\n",
    "\n",
    "    newRow = {\n",
    "        'Dataset': datasetName,\n",
    "        'DataSize': len(x),\n",
    "        'TrainingAccuracy': trainAccuracy,\n",
    "        'ValidationAccuracy': dataAccuracy\n",
    "    }\n",
    "\n",
    "    results.loc[len(results)] = newRow\n",
    "\n",
    "print(results)    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "### Answers\n",
    "1. These were interesting examples,  from the control, (the full data set), we can see that the small dataset increased in training accuracy, and decreased in validation accuracy.  While these numbers were small changes, the effect is still there.  from this,  we can see that as we decrease the size of our dataset for training,  the ability of the model to be fit for more cases decreases, and its model is more effected by different edge cases, or randomness.  We can see the difference from the fullDataSet to the smallDataSet that we are beginning to make a move to overfitting the data. In the case of the partial data set,  we see a huge discrepancy with both the trainingAccuracy and the validationAccuracy.  By only having two features to test with (the first two columns) we can see that it is hard for the model to fully understand what is going on when trying to predict a result.  This makes sense, as if we have less information in general, we can make less infomred decisions,  and the computer learning model is no different.  \n",
    "\n",
    "2. In the case of a spam email data set, a false positive would be identifying an categorizing a real, authentic email as spam. A false negative would be categorizing a spam email as an authentic one.  In this context, the false positive is worse.  We all live through a world of spam email. Getting spam email is something we constantly live with, and it doesnt affect our day to day.  Whereas a false positive in this case, would lead to an authentic, and potentially important email being sent to a trash folder, and perhaps important information being disregarded.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "Most of my code was homebrew, with influence from the past labs, some google/StackOverflow, and of course a sprinkle from GPT.  I completed the steps from the top down, like most any human would do, as the steps built on each other, a good indication of this is that they were numbered and generally people will follow steps in sequence. One thing I did do however, was to complete steps 3-5 the old fashioned way, with some very wet code before I refactored it into a loop with the different data sets in a dictionary.  The previous solution worked, but obviously wet code isnt anyones idea of a good time.  The GPT references were generally \"What is the syntax of...\"  or \"What is the difference between this and that\", or \"why would I do something this way, instead of this other way?\"  One thing in particular, was in splitting out the data for the 5% sample size.  I had initally used pd.sample,  howeve the instructions had said to use test_train_split,  upon some quick questions from GPT, I understood that the befits of the test_train_split was a more refined approach and less bias (from index) view of the data, supposedly.  I did have some challenges however, but eventually was able to track them down to operator error, largely my inability to spell things, and pythons inadherence to strongly typed code.  This was one of the things that GPT helped me with, in letting me know that Accuracy isnt spelled \"Acuuracy\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X: (1030, 8), with type <class 'pandas.core.frame.DataFrame'>\n",
      "Size of y: (1030,), with type <class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "279.0797166936134"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "# TO DO: Print size and type of X and y\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X, Y = yellowbrick.datasets.loaders.load_concrete(data_home=None, return_dataset=False)\n",
    "\n",
    "print(f\"Size of X: {X.shape}, with type {type(X)}\")\n",
    "print(f\"Size of y: {Y.shape}, with type {type(Y)}\")\n",
    "\n",
    "Y.var()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in x: 0\n",
      "missing values in y: 0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "\n",
    "missingValuesX = X.isna().sum().sum()\n",
    "missingValuesY = Y.isnull().sum()\n",
    "\n",
    "print(f\"Missing values in x: {missingValuesX}\")\n",
    "print(f\"missing values in y: {missingValuesY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5041945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "\n",
    "# Create the training sets\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(xTrain, yTrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "970c038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "yTestPred = model.predict(xTest)\n",
    "yTrainPred = model.predict(xTrain)\n",
    "\n",
    "\n",
    "\n",
    "mseTest = mean_squared_error(yTest, yTestPred)\n",
    "mseTrain = mean_squared_error(yTrain, yTrainPred)\n",
    "\n",
    "r2Test = r2_score(yTest, yTestPred)\n",
    "r2Train = r2_score(yTrain, yTrainPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     TrainingAccuracy  ValidationAccuracy\n",
      "MSE        110.345501           95.635335\n",
      "R2           0.609071            0.636898\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"TrainingAccuracy\": [mseTrain, r2Train],\n",
    "    \"ValidationAccuracy\": [mseTest, r2Test]\n",
    "}, index=['MSE', 'R2'])\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "\n",
    "I dont think so.  Unfortunatly for this assignment,  I come from a civil engineering background, and know that concrete is fairly predicable as humanity has been using it in some form for hundreds of years, so its a science that were pretty familiar with,  thus an R2 of ~0.6 isnt a particularly hot number for something like this.  Additionally, estimating the yeild of concrete off by an average of 10MPa, can be pretty catestrophic to construction, and thus, dont think this is a model that we should be putting any faith in. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "Lots of the code came from the first part of the assignment, with some changes for the patterns and different context and model types.  Some of it came from the ol' google/SO/GPT, and some of it was homebrew.  Again, the steps were completed in order as they were described, as it would have been impossible not to do this.  However the one step that I did look into in more detail, was a gander at the data, to understand more effectively what the model was trying to understand/estimate, and what information it had to do it with.  Understanding the context, with by background helped me know that this was not a linear relationship, and thus my expectations for this relationship was very limited.  \n",
    "\n",
    "Any of the code from generative sources was obviously modified for the context, and solution nescessary.  \n",
    "\n",
    "One of the only challenges I had, was to really understanding how the differences between measurements for validation and training accuracy between both model types, and how each validation parameter would work better on each model, and why they wouldnt work on the other, and better understanding their application.  This was understood better by some googling, youtube, and some light reading. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "This is a really good assignment to see the differences in validations when models fit,  vs when they do not fit, and are just not applicable.  Spam is a great example of classification models, whereas concrete yeild strength, will never ever be a linear relationship. In my opinion,  when you get accuracies of greater than 90%, and assuming that the training and validation accuraccy is relatively the same, (such that we are not overfitting the model) then I think it is a fair assumption that the model is relative to the data.  However,  similar to part one of this assignment where we had not enough information and only got ~60% accuracies,  we can see that this may look like an improper model, however it was really a case of just not enough information for the model to make representative and accurate estimations.  However, for the second part of the assignment,  even though we had what seemed to be more than enough data, we were still only able to get to ~0.6 on the R2,  or errors of around 10MPa,  which as mentioned before, are totally off in the cement world, to give perspective, there are concretes that dont even have a yeild of 10MPa, so this much difference is entirely too much, and just a case of the wrong model for the application. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "I liked that this was the first assignment where we had to do our own programming.  The labs are good, but often too rushed, and really just an example of \"write this code\", and not able to have enough time to really soak in the information and learn from it.  I have learned more from this assignment than from all the labs combined, and was happy to do it, even though it took me a while to complete, as I had to reference tons of different sources to get the knowledge. However I understand that is just me, and everyone learns differently.  I find that self learning and practical application is the best methods to learn.  \n",
    "\n",
    "I think its awesome how approachable and easy it really is to apply machine learning systems, however I do understand the dark side of machine learning also, that most of the work is cleaning the data, and so these beautiful yellowbrick datasets arent soemthing that we would likely ever see in the real world.  I would like to see some more examples where we can learn some more helpful approaches to data cleaning, even though that is everyones least favorite task, Id like to understand how to do it more effectively and efficiently. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47623d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "*ANSWER HERE*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
